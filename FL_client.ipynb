{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e82ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syft is imported\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "   import syft as sy\n",
    "   print(\"Syft is imported\")\n",
    "except:\n",
    "   print(\"Syft is not installed. Please use the üßôüèΩ‚Äç‚ôÇÔ∏è Install Wizard above.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7812550d",
   "metadata": {},
   "source": [
    "The following code is demonstrate how to login to the Domain server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f71bae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to 192.168.31.57... done! \t Logging into nervous_lecun... done!\n",
      "\n",
      "**Warning**: The syft version on your system and the node are different.\n",
      "Version on your system: 0.6.0\n",
      "Version on the node: 0.7.0-beta.62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "   domain_client = sy.login(\n",
    "      port=8082,\n",
    "      email=\"info@openmined.org\",\n",
    "      password=\"Alextsai0429!\",\n",
    "      url=\"192.168.31.57\"\n",
    "   )\n",
    "except Exception as e:\n",
    "   print(\"Unable to login. Please check your domain is up with `!hagrid check localhost:8081`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b146ad50",
   "metadata": {},
   "source": [
    "Fetch all available network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fdbe2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "data": {
      "text/html": [
       "(no networks online - try syft.networks.all_networks to see offline networks)"
      ],
      "text/plain": [
       "<syft.registry.NetworkRegistry at 0xffff363f9cd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sy.networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fce24ea",
   "metadata": {},
   "source": [
    "VFL Concpet overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67b50a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitNN:\n",
    "    def __init__(self, models, optimizers):\n",
    "        self.models = models\n",
    "        self.optimizers = optimizers\n",
    "\n",
    "        self.data = []\n",
    "        self.remote_tensors = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        data = []\n",
    "        remote_tensors = []\n",
    "\n",
    "        data.append(self.models[0](x))\n",
    "\n",
    "        if data[-1].location == self.models[1].location:\n",
    "            remote_tensors.append(data[-1].detach().requires_grad_())\n",
    "        else:\n",
    "            remote_tensors.append(\n",
    "                data[-1].detach().move(self.models[1].location).requires_grad_()\n",
    "            )\n",
    "\n",
    "        i = 1\n",
    "        while i < (len(models) - 1):\n",
    "            data.append(self.models[i](remote_tensors[-1]))\n",
    "\n",
    "            if data[-1].location == self.models[i + 1].location:\n",
    "                remote_tensors.append(data[-1].detach().requires_grad_())\n",
    "            else:\n",
    "                remote_tensors.append(\n",
    "                    data[-1].detach().move(self.models[i + 1].location).requires_grad_()\n",
    "                )\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        data.append(self.models[i](remote_tensors[-1]))\n",
    "\n",
    "        self.data = data\n",
    "        self.remote_tensors = remote_tensors\n",
    "\n",
    "        return data[-1]\n",
    "\n",
    "    def backward(self):\n",
    "        for i in range(len(models) - 2, -1, -1):\n",
    "            if self.remote_tensors[i].location == self.data[i].location:\n",
    "                grads = self.remote_tensors[i].grad.copy()\n",
    "            else:\n",
    "                grads = self.remote_tensors[i].grad.copy().move(self.data[i].location)\n",
    "    \n",
    "            self.data[i].backward(grads)\n",
    "\n",
    "    def zero_grads(self):\n",
    "        for opt in self.optimizers:\n",
    "            opt.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        for opt in self.optimizers:\n",
    "            opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43782bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in /home/vscode/.local/lib/python3.9/site-packages (0.14.1)\n",
      "Requirement already satisfied: requests in /home/vscode/.local/lib/python3.9/site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/vscode/.local/lib/python3.9/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: torch in /home/vscode/.local/lib/python3.9/site-packages (from torchvision) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in /home/vscode/.local/lib/python3.9/site-packages (from torchvision) (4.0.0)\n",
      "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.9/site-packages (from torchvision) (1.21.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/vscode/.local/lib/python3.9/site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.9/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vscode/.local/lib/python3.9/site-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'QuantStub' from 'torch.ao.quantization' (/home/vscode/.local/lib/python3.9/site-packages/torch/ao/quantization/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m../\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, transforms\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn, optim\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m MNIST\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/__init__.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, io, models, ops, transforms, utils\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mextension\u001b[39;00m \u001b[39mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m      9\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/models/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mswin_transformer\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmaxvit\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m detection, optical_flow, quantization, segmentation, video\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m \u001b[39mimport\u001b[39;00m get_model, get_model_builder, get_model_weights, get_weight, list_models\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/models/quantization/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgooglenet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39minception\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmobilenet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresnet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mshufflenetv2\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/models/quantization/mobilenet.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmobilenetv2\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401, F403\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmobilenetv3\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401, F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmobilenetv2\u001b[39;00m \u001b[39mimport\u001b[39;00m __all__ \u001b[39mas\u001b[39;00m mv2_all\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/models/quantization/mobilenetv2.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Optional, Union\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn, Tensor\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mao\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantization\u001b[39;00m \u001b[39mimport\u001b[39;00m DeQuantStub, QuantStub\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmobilenetv2\u001b[39;00m \u001b[39mimport\u001b[39;00m InvertedResidual, MobileNet_V2_Weights, MobileNetV2\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmisc\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2dNormActivation\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'QuantStub' from 'torch.ao.quantization' (/home/vscode/.local/lib/python3.9/site-packages/torch/ao/quantization/__init__.py)"
     ]
    }
   ],
   "source": [
    "!pip3 install torchvision\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import syft as sy\n",
    "\n",
    "from src.dataloader import VerticalDataLoader\n",
    "from src.psi.util import Client, Server\n",
    "from src.utils import add_ids\n",
    "\n",
    "hook = sy.TorchHook(torch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb4a0ac80907d7f44e1a5e88d3d3381b33e3dbedd3a24d113e876f30a0c46bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
